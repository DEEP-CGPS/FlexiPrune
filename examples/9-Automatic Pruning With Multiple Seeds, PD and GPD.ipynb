{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Definition of arguments for function usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('..')\n",
    "sys.path.append(os.path.abspath(\"../flexiprune\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1- Definition of arguments for function usage\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from flexiprune import *\n",
    "import argparse\n",
    "sys.argv = ['']\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Parameters for training')\n",
    "\n",
    "parser.add_argument('--model_architecture', type=str, default=\"VGG16\", \n",
    "                    help='Specify the architecture of the model (e.g., VGG16, AlexNet, etc.).')\n",
    "\n",
    "parser.add_argument('--method', type=str, default=\"random\", \n",
    "                    help='Specify the training method (e.g., SenpisFaster, random, weight).')\n",
    "\n",
    "parser.add_argument('--dataset', type=str, default=\"CIFAR10\", \n",
    "                    help='Specify the dataset for training (e.g., CIFAR10, \"Name of custom dataset\").')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int, default=8, \n",
    "                    help='Set the batch size for training.')\n",
    "\n",
    "parser.add_argument('--num_epochs', type=int, default=1, \n",
    "                    help='Specify the number of training epochs.')\n",
    "\n",
    "parser.add_argument('--learning_rate', type=float, default=1e-3, \n",
    "                    help='Set the learning rate for the optimizer.')\n",
    "\n",
    "parser.add_argument('--optimizer_val', type=str, default=\"SGD\", \n",
    "                    help='Specify the optimizer for training (e.g., SGD, Adam, etc.).')\n",
    "\n",
    "parser.add_argument('--model_type', type=str, default=\"UNPRUNED\", \n",
    "                    help='Specify the type of the model (e.g., PRUNED or UNPRUNED).')\n",
    "\n",
    "parser.add_argument('--device', type=str, default=None, \n",
    "                    help='Specify the device for training (e.g., \"cuda:0\" for GPU).')\n",
    "\n",
    "parser.add_argument('--model_input', default=torch.ones((1, 3, 224, 224)), \n",
    "                    help='Input tensor for the model (default is a tensor of ones).')\n",
    "\n",
    "parser.add_argument('--eval_metric', default=\"accuracy\", \n",
    "                    help='Specify the evaluation metric (e.g., accuracy, f1).')\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=23, \n",
    "                    help='Set the seed for random pruning operations.')\n",
    "\n",
    "parser.add_argument('--list_pruning', type=list, \n",
    "                    default=[], \n",
    "                    help='Specify the list of pruning ratios for each layer.')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.device is None:\n",
    "    import torch\n",
    "    args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model, DATASET and TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(10, args)\n",
    "train_loader, test_loader, num_classes, trainset = get_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(train_loader = train_loader,\n",
    "            test_loader = test_loader,\n",
    "            model = model,\n",
    "            num_classes = num_classes,\n",
    "            args = args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_seeds = [23,42,1234]\n",
    "\n",
    "GPR_LIST = [50,30,20]\n",
    "PD_LIST = [1,2,3,4,5]\n",
    "model_type = args.model_type\n",
    "obj_pd = PruningDistributionCalculator(model = args.model_architecture)\n",
    "\n",
    "for GPR in GPR_LIST:\n",
    "    for PD in PD_LIST:\n",
    "        args.list_pruning = obj_pd.calculate(GPR = GPR, PD = PD)\n",
    "        print(args.list_pruning)\n",
    "        for seed in list_seeds:\n",
    "            args.seed = seed\n",
    "            #original model unpruned\n",
    "            args.model_type = model_type\n",
    "            model = torch.load(f'models/{args.dataset}/{args.model_architecture}_{args.dataset}_{args.model_type}.pth',weights_only = False)\n",
    "            model.to(args.device)\n",
    "            args.model_type = f'PD{PD}_GPR-{GPR}_PRUNED_SEED_{seed}'\n",
    "            #prune original model\n",
    "            prune_model(model,num_classes,trainset, args)\n",
    "            #retraining pruned model\n",
    "            args.model_type = f'PD{PD}_GPR-{GPR}_PRUNED_FT_SEED_{seed}'\n",
    "            train_model(\n",
    "                train_loader = train_loader,\n",
    "                test_loader = test_loader,\n",
    "                model = model,\n",
    "                num_classes = num_classes,\n",
    "                args = args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flexiprune_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
