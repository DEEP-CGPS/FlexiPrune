{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Definition of arguments for function usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1- Definition of arguments for function usage\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from pruningdistribution import *\n",
    "import argparse\n",
    "sys.argv = ['']\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Parameters for training')\n",
    "\n",
    "parser.add_argument('--model_architecture', type=str, default=\"VGG16\", \n",
    "                    help='Specify the architecture of the model (e.g., VGG16, AlexNet, etc.).')\n",
    "\n",
    "parser.add_argument('--method', type=str, default=\"random\", \n",
    "                    help='Specify the training method (e.g., SenpisFaster, random, weight).')\n",
    "\n",
    "parser.add_argument('--dataset', type=str, default=\"CIFAR10\", \n",
    "                    help='Specify the dataset for training (e.g., CIFAR10, \"Name of custom dataset\").')\n",
    "\n",
    "parser.add_argument('--batch_size', type=int, default=8, \n",
    "                    help='Set the batch size for training.')\n",
    "\n",
    "parser.add_argument('--num_epochs', type=int, default=1, \n",
    "                    help='Specify the number of training epochs.')\n",
    "\n",
    "parser.add_argument('--learning_rate', type=float, default=1e-3, \n",
    "                    help='Set the learning rate for the optimizer.')\n",
    "\n",
    "parser.add_argument('--optimizer_val', type=str, default=\"SGD\", \n",
    "                    help='Specify the optimizer for training (e.g., SGD, Adam, etc.).')\n",
    "\n",
    "parser.add_argument('--model_type', type=str, default=\"UNPRUNED\", \n",
    "                    help='Specify the type of the model (e.g., PRUNED or UNPRUNED).')\n",
    "\n",
    "parser.add_argument('--device', type=str, default=None, \n",
    "                    help='Specify the device for training (e.g., \"cuda:0\" for GPU).')\n",
    "\n",
    "parser.add_argument('--model_input', default=torch.ones((1, 3, 224, 224)), \n",
    "                    help='Input tensor for the model (default is a tensor of ones).')\n",
    "\n",
    "parser.add_argument('--eval_metric', default=\"accuracy\", \n",
    "                    help='Specify the evaluation metric (e.g., accuracy, f1).')\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=23, \n",
    "                    help='Set the seed for random pruning operations.')\n",
    "\n",
    "parser.add_argument('--list_pruning', type=list, \n",
    "                    default=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0], \n",
    "                    help='Specify the list of pruning ratios for each layer.')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.device is None:\n",
    "    import torch\n",
    "    args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model, DATASET and TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(10, args)\n",
    "train_loader, test_loader, num_classes, trainset = get_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(train_loader = train_loader,\n",
    "            test_loader = test_loader,\n",
    "            model = model,\n",
    "            num_classes = num_classes,\n",
    "            args = args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original model unpruned\n",
    "model = torch.load(f'models/{args.dataset}/{args.model_architecture}_{args.dataset}_{args.model_type}.pth')\n",
    "model.to(args.device)\n",
    "args.model_type = f'your_model_name_with_out_fine_tunning'\n",
    "#prune original model\n",
    "prune_model(model,num_classes,trainset, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retraining pruned model\n",
    "args.model_type = f'your_model_name_with_fine_tunning'\n",
    "train_model(\n",
    "            train_loader = train_loader,\n",
    "            test_loader = test_loader,\n",
    "            model = model,\n",
    "            num_classes = num_classes,\n",
    "            args = args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "softwarexdistri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
